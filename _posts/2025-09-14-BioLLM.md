---
layout: post # 指定文章佈局，通常是 post
title: BioLLM
date: 2025-09-14 10:00:00 +0800 # 發表日期和時間 (請根據您當前的時區調整 +0800 代表 UTC+8)
categories: [Lecture] # 文章分類，您可以自訂
tags: [GenAI] # 文章標籤，您可以自訂
description: Sparse-AutoEncoder, Transcoder
mathjax: false # 如果這篇文章不需要顯示數學公式，請設false
comments: false # 如果這篇文章需要啟用評論，請設為 true

---
## BioLLM

### [SAE (Sparse Autoencoder)](https://medium.com/@falconives/day-33-sparse-autoencoder-sae-a9b29a1628f4)
**Lecture**: [CS294A Lecture notes by Andrew Ng](https://web.stanford.edu/class/cs294a/sparseAutoencoder.pdf)<br>
![](https://www.researchgate.net/publication/338158142/figure/fig1/AS:839836831346688@1577244112086/Basic-architecture-of-sparse-auto-encoder.ppm)

### SAE survey
**Paper**: [A Survey on Sparse Autoencoders: Interpreting the Internal Mechanisms of Large Language Models](https://arxiv.org/html/2503.05613v3)<br>
![](https://arxiv.org/html/2503.05613v3/x1.png)

---
### Transcoder
**Paper**: [Transcoders Find Interpretable LLM Feature Circuits](https://arxiv.org/html/2406.11944v2)<br>
**Code**: [Transcoder-circuits: reverse-engineering LLM circuits with transcoders](https://github.com/jacobdunefsky/transcoder_circuits/)<br>

---
### Sparse Crosscoders
**Paper**: [Sparse Crosscoders for Cross-Layer Features and Model Diffing](https://transformer-circuits.pub/2024/crosscoders/index.html)<br>

---
### SmolLM2
**Paper**: [SmolLM2: When Smol Goes Big — Data-Centric Training of a Small Language Model](https://arxiv.org/html/2502.02737v1)<br>
**Model**: [SmolLM2](https://huggingface.co/collections/HuggingFaceTB/smollm2-6723884218bcda64b34d7db9)<br>
State-of-the-art compact LLMs for on-device applications: 1.7B, 360M, 135M<br>
**Dataset**: [EleutherAI/SmolLM2-135M-10B](https://huggingface.co/datasets/EleutherAI/SmolLM2-135M-10B)<br>

---
### sparify
**Dataset** : []()<br>
**Code**: [https://github.com/EleutherAI/sparsify](https://github.com/EleutherAI/sparsify)<br>

```
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

tokenizer = AutoTokenizer.from_pretrained("meta-llama/Meta-Llama-3-8B")
inputs = tokenizer("Hello, world!", return_tensors="pt")

with torch.inference_mode():
    model = AutoModelForCausalLM.from_pretrained("meta-llama/Meta-Llama-3-8B")
    outputs = model(**inputs, output_hidden_states=True)

    latent_acts = []
    for sae, hidden_state in zip(saes.values(), outputs.hidden_states):
        # (N, D) input shape expected
        hidden_state = hidden_state.flatten(0, 1)
        latent_acts.append(sae.encode(hidden_state))

# Do stuff with the latent activations
```

---
### Evo2
**Paper**: [Genome modeling and design across all domains of life with Evo 2](https://www.biorxiv.org/content/10.1101/2025.02.18.638918v1)<br>
**Code**: [https://github.com/ArcInstitute/evo2](https://github.com/ArcInstitute/evo2)<br>
Evo 2: Genome modeling and design across all domains of life

---
### CellVerse
**Paper**: [CellVerse: Do Large Language Models Really Understand Cell Biology?](https://arxiv.org/abs/2505.07865)<br>
![](https://arxiv.org/html/2505.07865v1/x2.png)

---
### C2S (cell2sentence)
**Paper**: [Scaling Large Language Models for Next-Generation Single-Cell Analysis](https://www.biorxiv.org/content/10.1101/2025.04.14.648850v2)<br>
**model**: [C2S-Scale-Gemma-2-2B](https://huggingface.co/vandijklab/C2S-Scale-Gemma-2-2B), [C2S-Scale-Gemma-2-27B)(https://huggingface.co/vandijklab/C2S-Scale-Gemma-2-27B)<br>
**Code**: [https://github.com/vandijklab/cell2sentence](https://github.com/vandijklab/cell2sentence)<br>
![](https://github.com/vandijklab/cell2sentence/raw/master/c2s_overview_figure.png)

---
### Training Transcoder on C2S
**Paper**: [Transcoder-based Circuit Analysis for Interpretable Single-Cell Foundation Models](https://arxiv.org/html/2509.14723v1)<br>
**model**: [vandijklab/C2S-Pythia-410m-cell-type-prediction](https://huggingface.co/vandijklab/C2S-Pythia-410m-cell-type-prediction)<br>

<br>
<br>

*This site was last updated {{ site.time | date: "%B %d, %Y" }}.*
